import time
import mteb
import importlib.metadata as metadata
from importlib.metadata import version
from mteb.mteb.evaluation import MTEB
from sentence_transformers import SentenceTransformer
import torch


def ed_calc(x):
    M = x.shape[0]
    x_expanded = x.unsqueeze(1).expand(-1, M, -1)
    ed_sum = torch.norm(x_expanded - x, dim=2).sum()
    return ed_sum / (M * M)

def energy_calc(x, y):
    M = x.shape[0]
    N = y.shape[0]

    # Expand tensors to create all pairs of vectors
    x_expanded = x.unsqueeze(1).expand(-1, N, -1)
    y_expanded = y.unsqueeze(0).expand(M, -1, -1)
    
    # Compute pairwise squared Euclidean distances
    pairwise_diff = x_expanded - y_expanded
    squared_distances = torch.sum(pairwise_diff ** 2, dim=2)

    # Sum up squared distances and scale by (M * N)
    ed_sum = torch.sum(torch.sqrt(squared_distances))

    return 2 * ed_sum / (M * N)

def energy_distance(x, y):

    num_queries = len(x) #number of queries
    num_documents = len(y) #number of documents

    print("Num queries:", num_queries)
    print("Num documents:", num_documents)

    #Pre-calculate energy for all queries
    ed_queries = torch.stack([ed_calc(query) for query in x])

    #Create a tensor of shape M*N filled with zeros
    tensor = torch.zeros(num_queries, num_documents)

    for i in range(num_queries):
      ed_query = ed_queries[i] #store energy calculation of query to improve runtime
      for j in range(num_documents):
        #print("Query: ", i)
        #print("Document: ", j)
        tensor[i][j] = energy_calc(x[i], y[j].reshape(1,-1)).item() - ed_query.item()
    #print("Answer ", tensor.shape, type(tensor))
    return tensor



# Define the sentence-transformers model name
model_name = "ed-all-MiniLM-L6-v2"
model = SentenceTransformer("energy-distance/models/ed-all-MiniLM-L6-v2_TripletLoss_3")

query = ["A Direct Search Method to solve Economic Dispatch Problem with Valve-Point Effect"]
queries = ["A Direct Search Method to solve Economic Dispatch Problem with Valve-Point Effect", "Bearish-Bullish Sentiment Analysis on Financial Microblogs", 
"Predicting defects in SAP Java code: An experience report", "Active-Metric Learning for Classification of Remotely Sensed Hyperspectral Images",
"Ad Hoc Retrieval Experiments Using WordNet and Automatically Constructed Thesauri"]
documents = ["An evolutionary recurrent network which automates the design of recurrent neural/fuzzy networks using a new evolutionary learning algorithm is proposed in this paper. This new evolutionary learning algorithm is based on a hybrid of genetic algorithm (GA) and particle swarm optimization (PSO), and is thus called HGAPSO. In HGAPSO, individuals in a new generation are created, not only by crossover and mutation operation as in GA, but also by PSO. The concept of elite strategy is adopted in HGAPSO, where the upper-half of the best-performing individuals in a population are regarded as elites. However, instead of being reproduced directly to the next generation, these elites are first enhanced. The group constituted by the elites is regarded as a swarm, and each elite corresponds to a particle within it. In this regard, the elites are enhanced by PSO, an operation which mimics the maturing phenomenon in nature. These enhanced elites constitute half of the population in the new generation, whereas the other half is generated by performing crossover and mutation operation on these enhanced elites. HGAPSO is applied to recurrent neural/fuzzy network design as follows. For recurrent neural network, a fully connected recurrent neural network is designed and applied to a temporal sequence production problem. For recurrent fuzzy network design, a Takagi-Sugeno-Kang-type recurrent fuzzy network is designed and applied to dynamic plant control. The performance of HGAPSO is compared to both GA and PSO in these recurrent networks design problems, demonstrating its superiority.",
"Dynamic economic dispatch (DED) is one of the main functions of power generation operation and control. It determines the optimal settings of generator units with predicted load demand over a certain period of time. The objective is to operate an electric power system most economically while the system is operating within its security limits. This paper proposes a new hybrid methodology for solving DED. The proposed method is developed in such a way that a simple evolutionary programming (EP) is applied as a based level search, which can give a good direction to the optimal global region, and a local search sequential quadratic programming (SQP) is used as a fine tuning to determine the optimal solution at the final. Ten units test system with nonsmooth fuel cost function is used to illustrate the effectiveness of the proposed method compared with those obtained from EP and SQP alone.",
"It's not surprisingly when entering this site to get the book. One of the popular books now is the genetic fuzzy systems evolutionary tuning and learning of fuzzy knowledge bases. You may be confused because you can't find the book in the book store around your city. Commonly, the popular book will be sold quickly. And when you have found the store to buy the book, it will be so hurt when you run out of it. This is why, searching for this popular book in this website will give you benefit. You will not run out of this book.",
"In this paper, we introduce a new parameter, called inertia weight, into the original particle swarm optimizer. Simulations have been done to illustrate the signilicant and effective impact of this new parameter on the particle swarm optimizer.",
"This paper proposes a recurrent fuzzy neural network (RFNN) structure for identifying and controlling nonlinear dynamic systems. The RFNN is inherently a recurrent multilayered connectionist network for realizing fuzzy inference using dynamic fuzzy rules. Temporal relations are embedded in the network by adding feedback connections in the second layer of the fuzzy neural network (FNN). The RFNN expands the basic ability of the FNN to cope with temporal problems. In addition, results for the FNNfuzzy inference engine, universal approximation, and convergence analysis are extended to the RFNN. For the control problem, we present the direct and indirect adaptive control approaches using the RFNN. Based on the Lyapunov stability approach, rigorous proofs are presented to guarantee the convergence of the RFNN by choosing appropriate learning rates. Finally, the RFNN is applied in several simulations (time series prediction, identification, and control of nonlinear systems). The results confirm the effectiveness of the RFNN.",
"Recent reports of a high response to bodies in the fusiform face area (FFA) challenge the idea that the FFA is exclusively selective for face stimuli. We examined this claim by conducting a functional magnetic resonance imaging experiment at both standard (3.125 x 3.125 x 4.0 mm) and high resolution (1.4 x 1.4 x 2.0 mm). In both experiments, regions of interest (ROIs) were defined using data from blocked localizer runs. Within each ROI, we measured the mean peak response to a variety of stimulus types in independent data from a subsequent event-related experiment. Our localizer scans identified a fusiform body area (FBA), a body-selective region reported recently by Peelen and Downing (2005) that is anatomically distinct from the extrastriate body area. The FBA overlapped with and was adjacent to the FFA in all but two participants. Selectivity of the FFA to faces and FBA to bodies was stronger for the high-resolution scans, as expected from the reduction in partial volume effects. When new ROIs were constructed for the high-resolution experiment by omitting the voxels showing overlapping selectivity for both bodies and faces in the localizer scans, the resulting FFA* ROI showed no response above control objects for body stimuli, and the FBA* ROI showed no response above control objects for face stimuli. These results demonstrate strong selectivities in distinct but adjacent regions in the fusiform gyrus for only faces in one region (the FFA*) and only bodies in the other (the FBA*).",
"The energy usage of computer systems is becoming more important, especially for battery operated systems. Displays, disks, and cpus, in that order, use the most energy. Reducing the energy used by displays and disks has been studied elsewhere; this paper considers a new method for reducing the energy used by the cpu. We introduce a new metric for cpu energy performance, millions-of-instructions-per-joule (MIPJ). We examine a class of methods to reduce MIPJ that are characterized by dynamic control of system clock speed by the operating system scheduler. Reducing clock speed alone does not reduce MIPJ, since to do the same work the system must run longer. However, a number of methods are available for reducing energy with reduced clock-speed, such as reducing the voltage [Chandrakasan et al 1992][Horowitz 1993] or using reversible [Younis and Knight 1993] or adiabatic logic [Athas et al 1994]. What are the right scheduling algorithms for taking advantage of reduced clock-speed, especially in the presence of applications demanding ever more instructions-per-second? We consider several methods for varying the clock speed dynamically under control of the operating system, and examine the performance of these methods against workstation traces. The primary result is that by adjusting the clock speed at a fine grain, substantial CPU energy can be saved with a limited impact on performance.",
"Mobility prediction is one of the most essential issues that need to be explored for mobility management in mobile computing systems. In this paper, we propose a new algorithm for predicting the next inter-cell movement of a mobile user in a Personal Communication Systems network. In the first phase of our threephase algorithm, user mobility patterns are mined from the history of mobile user trajectories. In the second phase, mobility rules are extracted from these patterns, and in the last phase, mobility predictions are accomplished by using these rules. The performance of the proposed algorithm is evaluated through simulation as compared to two other prediction methods. The performance results obtained in terms of Precision and Recall indicate that our method can make more accurate predictions than the other methods. 2004 Elsevier B.V. All rights reserved.",
"We study the problem of structural graph clustering, a fundamental problem in managing and analyzing graph data. Given an undirected unweighted graph, structural graph clustering is to assign vertices to clusters, and to identify the sets of hub vertices and outlier vertices as well, such that vertices in the same cluster are densely connected to each other while vertices in different clusters are loosely connected. In this paper, we develop a new two-step paradigm for scalable structural graph clustering based on our three observations. Then, we present a <inline-formula> <tex-math notation=LaTeX>$\mathsf {pSCAN}$</tex-math><alternatives> <inline-graphic xlink:href=chang-ieq2-2618795.gif/></alternatives></inline-formula> approach, within the paradigm, aiming to reduce the number of structural similarity computations, and propose optimization techniques to speed up checking whether two vertices are structure-similar. <inline-formula><tex-math notation=LaTeX>$\mathsf {pSCAN}$ </tex-math><alternatives><inline-graphic xlink:href=chang-ieq3-2618795.gif/></alternatives></inline-formula> outputs exactly the same clusters as the existing approaches <inline-formula><tex-math notation=LaTeX>$\mathsf {SCAN}$ </tex-math><alternatives><inline-graphic xlink:href=chang-ieq4-2618795.gif/></alternatives></inline-formula> and <inline-formula><tex-math notation=LaTeX>$\mathsf {SCAN\text{++}}$</tex-math><alternatives> <inline-graphic xlink:href=chang-ieq5-2618795.gif/></alternatives></inline-formula>, and we prove that <inline-formula><tex-math notation=LaTeX>$\mathsf {pSCAN}$</tex-math><alternatives> <inline-graphic xlink:href=chang-ieq6-2618795.gif/></alternatives></inline-formula> is worst-case optimal. Moreover, we propose efficient techniques for updating the clusters when the input graph dynamically changes, and we also extend our techniques to other similarity measures, e.g., Jaccard similarity. Performance studies on large real and synthetic graphs demonstrate the efficiency of our new approach and our dynamic cluster maintenance techniques. Noticeably, for the twitter graph with 1 billion edges, our approach takes 25 minutes while the state-of-the-art approach cannot finish even after 24 hours.",
"Iron, the most ubiquitous of the transition metals and the fourth most plentiful element in the Earth's crust, is the structural backbone of our modern infrastructure. It is therefore ironic that as a nanoparticle, iron has been somewhat neglected in favor of its own oxides, as well as other metals such as cobalt, nickel, gold, and platinum. This is unfortunate, but understandable. Iron's reactivity is important in macroscopic applications (particularly rusting), but is a dominant concern at the nanoscale. Finely divided iron has long been known to be pyrophoric, which is a major reason that iron nanoparticles have not been more fully studied to date. This extreme reactivity has traditionally made iron nanoparticles difficult to study and inconvenient for practical applications. Iron however has a great deal to offer at the nanoscale, including very potent magnetic and catalytic properties. Recent work has begun to take advantage of iron's potential, and work in this field appears to be blossoming.",
"ADVERTIMENT. La consulta d’aquesta tesi queda condicionada a l’acceptació de les següents condicions d'ús: La difusió d’aquesta tesi per mitjà del servei TDX (www.tdx.cat) i a través del Dipòsit Digital de la UB (diposit.ub.edu) ha estat autoritzada pels titulars dels drets de propietat intel·lectual únicament per a usos privats emmarcats en activitats d’investigació i docència. No s’autoritza la seva reproducció amb finalitats de lucre ni la seva difusió i posada a disposició des d’un lloc aliè al servei TDX ni al Dipòsit Digital de la UB. No s’autoritza la presentació del seu contingut en una finestra o marc aliè a TDX o al Dipòsit Digital de la UB (framing). Aquesta reserva de drets afecta tant al resum de presentació de la tesi com als seus continguts. En la utilització o cita de parts de la tesi és obligat indicar el nom de la persona autora.",
"This paper describes the genesis of Gualzru, a robot commissioned by a large Spanish technological company to provide advertisement services in open public spaces. Gualzru has to stand by at an interactive panel observing the people passing by and, at some point, select a promising candidate and approach her to initiate a conversation. After a small verbal interaction, the robot is supposed to convince the passerby to walk back to the panel, leaving the rest of the selling task to an interactive software embedded in it. The whole design and building process took less than three years of team composed of five groups at different geographical locations. We describe here the lessons learned during this period of time, from different points of view including the hardware, software, architectural decisions and team collaboration issues.",
"Treatment effects can be estimated from observational data as the difference in potential outcomes. In this paper, we address the challenge of estimating the potential outcome when treatment-dose levels can vary continuously over time. Further, the outcome variable may not be measured at a regular frequency. Our proposed solution represents the treatment response curves using linear time-invariant dynamical systems—this provides a flexible means for modeling response over time to highly variable dose curves. Moreover, for multivariate data, the proposed method: uncovers shared structure in treatment response and the baseline across multiple markers; and, flexibly models challenging correlation structure both across and within signals over time. For this, we build upon the framework of multiple-output Gaussian Processes. On simulated and a challenging clinical dataset, we show significant gains in accuracy over stateof-the-art models.",
"A planar helical antenna is presented for achieving wideband end-fire radiation of circular polarization while maintaining a very low profile. The helix is formed using printed strips with straight-edge connections implemented by plated viaholes. The currents flowing on the strips and along via-holes of the helix contribute to the horizontal and vertical polarizations, respectively. Besides, the current on the ground plane is utilized to weaken the strong amplitude of the horizontal electric field generated by the one on the strips. Thus, a good circular polarization can be achieved. Furthermore, a tapered helix and conducting side-walls are employed to broaden the axial ratio (AR) bandwidth as well as to improve the end-fire radiation pattern. The designed antenna operates at the center frequency of 10 GHz. Simulated results show that the planar helical antenna achieves wide-impedance bandwidth (|S11| <; -10 dB) from 7.4 to 12.8 GHz (54%) and 3-dB AR bandwidth from 8.2 to 11.6 GHz (34%), while retaining a thickness of only 0.11λ0 at the center frequency. A prototype of the proposed antenna is fabricated and tested. Measured results are in good agreement with simulated ones.",
"Context Common concerns when using low-calorie diets as a treatment for obesity are the reduction in fat-free mass, mostly muscular mass, that occurs together with the fat mass (FM) loss, and determining the best methodologies to evaluate body composition changes. Objective This study aimed to evaluate the very-low-calorie ketogenic (VLCK) diet-induced changes in body composition of obese patients and to compare 3 different methodologies used to evaluate those changes. Design Twenty obese patients followed a VLCK diet for 4 months. Body composition assessment was performed by dual-energy X-ray absorptiometry (DXA), multifrequency bioelectrical impedance (MF-BIA), and air displacement plethysmography (ADP) techniques. Muscular strength was also assessed. Measurements were performed at 4 points matched with the ketotic phases (basal, maximum ketosis, ketosis declining, and out of ketosis). Results After 4 months the VLCK diet induced a -20.2 ± 4.5 kg weight loss, at expenses of reductions in fat mass (FM) of -16.5 ± 5.1 kg (DXA), -18.2 ± 5.8 kg (MF-BIA), and -17.7 ± 9.9 kg (ADP). A substantial decrease was also observed in the visceral FM. The mild but marked reduction in fat-free mass occurred at maximum ketosis, primarily as a result of changes in total body water, and was recovered thereafter. No changes in muscle strength were observed. A strong correlation was evidenced between the 3 methods of assessing body composition. Conclusion The VLCK diet-induced weight loss was mainly at the expense of FM and visceral mass; muscle mass and strength were preserved. Of the 3 body composition techniques used, the MF-BIA method seems more convenient in the clinical setting.",
"According to art theory, pictorial balance acts to unify picture elements into a cohesive composition. For asymmetrical compositions, balancing elements is thought to be similar to balancing mechanical weights in a framework of symmetry axes. Assessment of preference for balance (APB), based on the symmetry-axes framework suggested in Arnheim R, 1974 Art and Visual Perception: A Psychology of the Creative Eye (Berkeley, CA: University of California Press), successfully matched subject balance ratings of images of geometrical shapes over unlimited viewing time. We now examine pictorial balance perception of Japanese calligraphy during first fixation, isolated from later cognitive processes, comparing APB measures with results from balance-rating and comparison tasks. Results show high between-task correlation, but low correlation with APB. We repeated the rating task, expanding the image set to include five rotations of each image, comparing balance perception of artist and novice participant groups. Rotation has no effect on APB balance computation but dramatically affects balance rating, especially for art experts. We analyze the variety of rotation effects and suggest that, rather than depending on element size and position relative to symmetry axes, first fixation balance processing derives from global processes such as grouping of lines and shapes, object recognition, preference for horizontal and vertical elements, closure, and completion, enhanced by vertical symmetry.",
"Background: Smoking has long been suspected to be a risk factor for cervical cancer. However, not all previous studies have properly controlled for the effect of human papillomavirus (HPV) infection, which has now been established as a virtually necessary cause of cervical cancer. To evaluate the role of smoking as a cofactor of progression from HPV infection to cancer, we performed a pooled analysis of 10 previously published case–control studies. This analysis is part of a series of analyses of cofactors of HPV in the aetiology of cervical cancer. Methods: Data were pooled from eight case–control studies of invasive cervical carcinoma (ICC) and two of carcinoma in situ (CIS) from four continents. All studies used a similar protocol and questionnaires and included a PCR-based evaluation of HPV DNA in cytological smears or biopsy specimens. Only subjects positive for HPV DNA were included in the analysis. A total of 1463 squamous cell ICC cases were analyzed, along with 211 CIS cases, 124 adeno- or adeno-squamous ICC cases and 254 control women. Pooled odds ratios (OR) and 95% confidence intervals (CI) were estimated using logistic regression models controlling for sexual and non-sexual confounding factors. Results: There was an excess risk for ever smoking among HPV positive women (OR 2.17 95%CI 1.46–3.22). When results were analyzed by histological type, an excess risk was observed among cases of squamous cell carcinoma for current smokers (OR 2.30, 95%CI 1.31–4.04) and ex-smokers (OR 1.80, 95%CI 0.95–3.44). No clear pattern of association with risk was detected for adenocarcinomas, although the number of cases with this histologic type was limited. Conclusions: Smoking increases the risk of cervical cancer among HPV positive women. The results of our study are consistent with the few previously conducted studies of smoking and cervical cancer that have adequately controlled for HPV infection. Recent increasing trends of smoking among young women could have a serious impact on cervical cancer incidence in the coming years.",
"This paper analyzes the main challenges associated with noninvasive, continuous, wearable, and long-term breathing monitoring. The characteristics of an acoustic breathing signal from a miniature sensor are studied in the presence of sources of noise and interference artifacts that affect the signal. Based on these results, an algorithm has been devised to detect breathing. It is possible to implement the algorithm on a single integrated circuit, making it suitable for a miniature sensor device. The algorithm is tested in the presence of noise sources on five subjects and shows an average success rate of 91.3% (combined true positives and true negatives).",
"We introduce a long short-term memory recurrent neural network (LSTM-RNN) approach for real-time facial animation, which automatically estimates head rotation and facial action unit activations of a speaker from just her speech. Specifically, the time-varying contextual non-linear mapping between audio stream and visual facial movements is realized by training a LSTM neural network on a large audio-visual data corpus. In this work, we extract a set of acoustic features from input audio, including Mel-scaled spectrogram, Mel frequency cepstral coefficients and chromagram that can effectively represent both contextual progression and emotional intensity of the speech. Output facial movements are characterized by 3D rotation and blending expression weights of a blendshape model, which can be used directly for animation. Thus, even though our model does not explicitly predict the affective states of the target speaker, her emotional manifestation is recreated via expression weights of the face model. Experiments on an evaluation dataset of different speakers across a wide range of affective states demonstrate promising results of our approach in real-time speech-driven facial animation.",
"Hierarchical Pitman-Yor Process priors are compelling methods for learning language models, outperforming point-estimate based methods. However, these models remain unpopular due to computational and statistical inference issues, such as memory and time usage, as well as poor mixing of sampler. In this work we propose a novel framework which represents the HPYP model compactly using compressed suffix trees. Then, we develop an efficient approximate inference scheme in this framework that has a much lower memory footprint compared to full HPYP and is fast in the inference time. The experimental results illustrate that our model can be built on significantly larger datasets compared to previous HPYP models, while being several orders of magnitudes smaller, fast for training and inference, and outperforming the perplexity of the state-of-the-art Modified Kneser-Ney countbased LM smoothing by up to 15%.",
"This paper introduces a new compositional framework for classifying color correction methods according to their two main computational units. The framework was used to dissect fifteen among the best color correction algorithms and the computational units so derived, with the addition of four new units specifically designed for this work, were then reassembled in a combinatorial way to originate about one hundred distinct color correction methods, most of which never considered before. The above color correction methods were tested on three different existing datasets, including both real and artificial color transformations, plus a novel dataset of real image pairs categorized according to the kind of color alterations induced by specific acquisition setups. Differently from previous evaluations, special emphasis was given to effectiveness in real world applications, such as image mosaicing and stitching, where robustness with respect to strong image misalignments and light scattering effects is required. Experimental evidence is provided for the first time in terms of the most recent perceptual image quality metrics, which are known to be the closest to human judgment. Comparative results show that combinations of the new computational units are the most effective for real stitching scenarios, regardless of the specific source of color alteration. On the other hand, in the case of accurate image alignment and artificial color alterations, the best performing methods either use one of the new computational units, or are made up of fresh combinations of existing units."
]

query_embeddings = model.encode(query, output_value="token_embeddings", convert_to_tensor=True)
document_embeddings = model.encode(documents, convert_to_tensor=True)

ans = energy_distance(query_embeddings, document_embeddings)

print(ans)



