{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../sentence-transformers_energydistance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/gtracy/src/sentence_transformers_energydistance\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence-transformers==2.8.0.dev0) (7.0.0)\n",
      "Collecting huggingface-hub>=0.15.1\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Requirement already satisfied: numpy in /home/gtracy/.local/lib/python3.8/site-packages (from sentence-transformers==2.8.0.dev0) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /home/gtracy/.local/lib/python3.8/site-packages (from sentence-transformers==2.8.0.dev0) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/gtracy/.local/lib/python3.8/site-packages (from sentence-transformers==2.8.0.dev0) (1.10.1)\n",
      "Collecting torch>=1.11.0\n",
      "  Using cached torch-2.3.0-cp38-cp38-manylinux1_x86_64.whl (779.1 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.8.0.dev0) (5.3.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gtracy/.local/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.8.0.dev0) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/gtracy/.local/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.8.0.dev0) (23.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.8.0.dev0) (2.22.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/gtracy/.local/lib/python3.8/site-packages (from scikit-learn->sentence-transformers==2.8.0.dev0) (3.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/gtracy/.local/lib/python3.8/site-packages (from scikit-learn->sentence-transformers==2.8.0.dev0) (1.3.2)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting triton==2.3.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\"\n",
      "  Using cached triton-2.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.0 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 74.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2024.4.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gtracy/.local/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.8.0.dev0) (2.1.5)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.8.0.dev0-py3-none-any.whl size=171189 sha256=58f43b06eef533b92aa6ecf7d49b4a6870cf61995a43c75b920e042957f067b6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-c0t8ffn0/wheels/63/c2/7b/fcc5e7170176a8fa9df47fd49bc215cf08f727a39e830790f7\n",
      "Successfully built sentence-transformers\n",
      "\u001b[31mERROR: torch 2.3.0 has requirement typing-extensions>=4.8.0, but you'll have typing-extensions 4.5.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: fsspec, filelock, tqdm, huggingface-hub, nvidia-nvtx-cu12, nvidia-cufft-cu12, networkx, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cuda-nvrtc-cu12, triton, mpmath, sympy, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, jinja2, nvidia-cuda-cupti-cu12, torch, tokenizers, regex, safetensors, transformers, sentence-transformers\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.3.1 huggingface-hub-0.23.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 regex-2024.4.28 safetensors-0.4.3 sentence-transformers-2.8.0.dev0 sympy-1.12 tokenizers-0.19.1 torch-2.3.0 tqdm-4.66.4 transformers-4.40.2 triton-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ../sentence_transformers_energydistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/gtracy/.local/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: sympy in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: jinja2 in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: triton==2.3.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (2.3.0)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: filelock in /home/gtracy/.local/lib/python3.8/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/gtracy/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gtracy/.local/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/gtracy/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (12.4.127)\n",
      "\u001b[31mERROR: tensorflow 2.13.1 has requirement keras<2.14,>=2.13.1, but you'll have keras 2.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.13.1 has requirement numpy<=1.24.3,>=1.22, but you'll have numpy 1.24.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.13.1 has requirement typing-extensions<4.6.0,>=3.6.6, but you'll have typing-extensions 4.11.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.5.0\n",
      "    Uninstalling typing-extensions-4.5.0:\n",
      "      Successfully uninstalled typing-extensions-4.5.0\n",
      "Successfully installed typing-extensions-4.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gtracy/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gtracy/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/gtracy/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "## Step 1: use an existing language model\n",
    "word_embedding_model = models.Transformer('distilroberta-base')\n",
    "\n",
    "## Step 2: use a pool function over the token embeddings\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "## Join steps 1 and 2 using the modules argument\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[K     |████████████████████████████████| 542 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/gtracy/.local/lib/python3.8/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pandas in /home/gtracy/.local/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets) (2.22.0)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.9.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/gtracy/.local/lib/python3.8/site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: filelock in /home/gtracy/.local/lib/python3.8/site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /home/gtracy/.local/lib/python3.8/site-packages (from datasets) (2024.3.1)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Using cached pyarrow-16.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.9 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.3.1)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "Collecting pyarrow-hotfix\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/gtracy/.local/lib/python3.8/site-packages (from datasets) (1.24.4)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/gtracy/.local/lib/python3.8/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gtracy/.local/lib/python3.8/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gtracy/.local/lib/python3.8/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/gtracy/.local/lib/python3.8/site-packages (from pandas->datasets) (2024.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Collecting async-timeout<5.0,>=4.0; python_version < \"3.11\"\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (308 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gtracy/.local/lib/python3.8/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gtracy/.local/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (2.8)\n",
      "Installing collected packages: xxhash, frozenlist, aiosignal, multidict, async-timeout, yarl, aiohttp, pyarrow, dill, multiprocess, pyarrow-hotfix, datasets\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.19.1 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-16.0.0 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_id = \"embedding-data/QQP_triplets\"\n",
    "#dataset_id = \"stanfordnlp/snli\"\n",
    "# dataset_id = \"embedding-data/sentence-compression\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The embedding-data/QQP_triplets dataset has 101762 examples.\n",
      "- Each example is a <class 'dict'> with a <class 'dict'> as value.\n",
      "- Examples look like this: {'set': {'query': 'Why in India do we not have one on one political debate as in USA?', 'pos': ['Why cant we have a public debate between politicians in India like the one in US?'], 'neg': ['Can people on Quora stop India Pakistan debate? We are sick and tired seeing this everyday in bulk?', 'Why do politicians, instead of having a decent debate on issues going in and around the world, end up fighting always?', 'Can educated politicians make a difference in India?', 'What are some unusual aspects about politics and government in India?', 'What is debate?', 'Why does civic public communication and discourse seem so hollow in modern India?', 'What is a Parliamentary debate?', \"Why do we always have two candidates at the U.S. presidential debate. yet the ballot has about 7 candidates? Isn't that a misrepresentation of democracy?\", 'Why is civic public communication and discourse so hollow in modern India?', \"Aren't the Presidential debates teaching our whole country terrible communication skills and why is deliberate misrepresentation even allowed?\", 'Why are most Indian politicians uneducated?', 'Does Indian political leaders capable of doing face to face debates while running for office?', 'What is wrong with the Indian political system and the environment it has built in connection with the people of India? Have parties divided people more?', 'What is a debate?', 'Why do we have legislative council in india?', 'Why does the office of president of India, being politically neutral, not ask for Population control in India?', \"Why don't we discuss tax and foreign policies more in Indian elections but are instead obsessed with socialist schemes?\", 'Why do Indian politicians lack nationalist thinking?', 'Do you hate indian politicians?', 'Is India facing more stessful times and politically charged atmosphere when compared to Congress regime?', 'Who is the best politician in India? Why?', \"We all know about the present condition of Indian politicians; they are all just using us to run their train, but still, they win elections and rule over us. Why aren't people giving their vote to NOTA?\", 'Who are clean politicians in India?', 'Why are you not believing in Democracy of India?', 'What does politics in India mean? What are they actually doing?', 'What are the strongest arguments for a debate in favour of brain drain in India and what sources must be used for making a good short speech?', 'Do we really need an election commission in India?', 'Why is there no concept of political correctness in India? Is it a good thing or a bad thing?', 'Why is population control not on agenda of any political party in India?', 'Who are some of the most dangerous or worst politicians in India?']}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"- The {dataset_id} dataset has {dataset['train'].num_rows} examples.\")\n",
    "print(f\"- Each example is a {type(dataset['train'][0])} with a {type(dataset['train'][0]['set'])} as value.\")\n",
    "print(f\"- Examples look like this: {dataset['train'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "train_examples = []\n",
    "train_data = dataset['train']['set']\n",
    "# For agility we only 1/2 of our available data\n",
    "n_examples = dataset['train'].num_rows // 2\n",
    "\n",
    "for i in range(n_examples):\n",
    "  example = train_data[i]\n",
    "  train_examples.append(InputExample(texts=[example['query'], example['pos'][0], example['neg'][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a <class 'list'> of length 50881 containing <class 'sentence_transformers.readers.InputExample.InputExample'>'s.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have a {type(train_examples)} of length {len(train_examples)} containing {type(train_examples[0])}'s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "train_loss = losses.ContrastiveLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.43it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.80it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.34it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.57it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.35it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.21it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:54<00:00, 58.87it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.24it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.03it/s]\n",
      "Iteration: 100%|██████████| 3181/3181 [00:53<00:00, 59.10it/s]\n",
      "Epoch: 100%|██████████| 10/10 [08:56<00:00, 53.65s/it]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ['/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/gtracy/.local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '../', '../sentence-transformers_energydistance']/results does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    628\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:501\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:472\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ['/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/gtracy/.local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '../', '../sentence-transformers_energydistance']/results does not exist."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "model_name = 'model-1'\n",
    "model_path = f'{os.getcwd()}/results/{model_name}.pth'\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
